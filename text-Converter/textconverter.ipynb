{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c08caf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSave this as: stable_table_detector.ipynb\\n\\nSTABLE BPHS TABLE DETECTION SYSTEM (NO PADDLEOCR)\\n\\nâœ“ Dual-method table detection:\\n  1. DETR Table Transformer (two-pass: 0.6, 0.4)\\n  2. OpenCV contour detection\\nâœ“ Merge & deduplicate overlapping boxes\\nâœ“ Google Vision OCR for multilingual text (Hindi, Sanskrit, English)\\nâœ“ Extremely stable - no crashes\\nâœ“ Save formatted text file + JSON with verification images\\n\\nInstallation:\\n!pip install opencv-python torch transformers pdf2image pillow google-cloud-vision\\n\\nEnv:\\nexport GOOGLE_APPLICATION_CREDENTIALS=\"vision_key.json\"\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save this as: stable_table_detector.ipynb\n",
    "\n",
    "STABLE BPHS TABLE DETECTION SYSTEM (NO PADDLEOCR)\n",
    "\n",
    "âœ“ Dual-method table detection:\n",
    "  1. DETR Table Transformer (two-pass: 0.6, 0.4)\n",
    "  2. OpenCV contour detection\n",
    "âœ“ Merge & deduplicate overlapping boxes\n",
    "âœ“ Google Vision OCR for multilingual text (Hindi, Sanskrit, English)\n",
    "âœ“ Extremely stable - no crashes\n",
    "âœ“ Save formatted text file + JSON with verification images\n",
    "\n",
    "Installation:\n",
    "!pip install opencv-python torch transformers pdf2image pillow google-cloud-vision\n",
    "\n",
    "Env:\n",
    "export GOOGLE_APPLICATION_CREDENTIALS=\"vision_key.json\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51e27782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: c:\\Users\\saini\\OneDrive\\Desktop\\IMG_Global_infotech\\ocr_env\\Scripts\\python.exe\n",
      "cv2: 4.6.0\n",
      "numpy: 1.26.4\n",
      "torch: 2.2.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"cv2:\", cv2.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"torch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8028dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 1: Imports and Setup\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from google.cloud import vision\n",
    "from transformers import DetrImageProcessor, TableTransformerForObjectDetection\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8ca9fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Output directory created: c:\\Users\\saini\\OneDrive\\Desktop\\IMG_Global_infotech\\final_output\n",
      "\n",
      "======================================================================\n",
      "ğŸ” SETUP VERIFICATION\n",
      "======================================================================\n",
      "âœ… PDF file found: bphs_table_samples 2.pdf\n",
      "âœ… Google credentials found\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration\n",
    "# ---------------- CONFIG ----------------\n",
    "\n",
    "PDF_PATH = \"bphs_table_samples 2.pdf\"\n",
    "OUTPUT_DIR = \"final_output\"\n",
    "DPI = 300\n",
    "TABLE_THRESHOLD_PASS1 = 0.6\n",
    "TABLE_THRESHOLD_PASS2 = 0.4\n",
    "IOU_THRESHOLD = 0.3  # Lower for better merging\n",
    "\n",
    "# Google Vision credentials path\n",
    "VISION_CREDENTIALS = r\"C:\\Users\\saini\\OneDrive\\Desktop\\IMG_Global_infotech\\google_credentials 1.json\"\n",
    "\n",
    "# Create output directory (with parents if needed)\n",
    "import os\n",
    "output_path = Path(OUTPUT_DIR)\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"âœ… Output directory created: {output_path.absolute()}\")\n",
    "\n",
    "# Verify setup\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” SETUP VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check PDF exists\n",
    "if os.path.exists(PDF_PATH):\n",
    "    print(f\"âœ… PDF file found: {PDF_PATH}\")\n",
    "else:\n",
    "    print(f\"âŒ PDF file NOT found: {PDF_PATH}\")\n",
    "    print(f\"   Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Check credentials exist\n",
    "if os.path.exists(VISION_CREDENTIALS):\n",
    "    print(f\"âœ… Google credentials found\")\n",
    "else:\n",
    "    print(f\"âŒ Google credentials NOT found\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31c4f1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing OCR system...\n",
      "âœ… Google Vision initialized (supports Hindi, Sanskrit, English)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize OCR Systems\n",
    "# ---------------- INITIALIZE CLIENTS ----------------\n",
    "\n",
    "print(\"Initializing OCR system...\")\n",
    "\n",
    "# Google Vision - Primary and most reliable OCR\n",
    "vision_client = vision.ImageAnnotatorClient.from_service_account_file(VISION_CREDENTIALS)\n",
    "print(\"âœ… Google Vision initialized (supports Hindi, Sanskrit, English)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7b5d370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading DETR Table Transformer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/table-transformer-detection were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DETR model loaded\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load Table Transformer Model\n",
    "# ---------------- TABLE TRANSFORMER MODEL ----------------\n",
    "\n",
    "print(\"\\nLoading DETR Table Transformer...\")\n",
    "processor = DetrImageProcessor.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "table_model = TableTransformerForObjectDetection.from_pretrained(\n",
    "    \"microsoft/table-transformer-detection\"\n",
    ")\n",
    "print(\"âœ… DETR model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d6ba899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Helper Functions\n",
    "# ---------------- HELPER FUNCTIONS ----------------\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate Intersection over Union of two boxes.\"\"\"\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "    \n",
    "    x1_i = max(x1_1, x1_2)\n",
    "    y1_i = max(y1_1, y1_2)\n",
    "    x2_i = min(x2_1, x2_2)\n",
    "    y2_i = min(y2_1, y2_2)\n",
    "    \n",
    "    if x2_i < x1_i or y2_i < y1_i:\n",
    "        return 0.0\n",
    "    \n",
    "    intersection = (x2_i - x1_i) * (y2_i - y1_i)\n",
    "    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def merge_boxes(boxes, iou_threshold=0.3):\n",
    "    \"\"\"Merge overlapping boxes from all detection methods.\"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    merged = []\n",
    "    used = [False] * len(boxes)\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        if used[i]:\n",
    "            continue\n",
    "            \n",
    "        current_box = list(boxes[i])\n",
    "        used[i] = True\n",
    "        \n",
    "        for j in range(i + 1, len(boxes)):\n",
    "            if used[j]:\n",
    "                continue\n",
    "                \n",
    "            iou = calculate_iou(current_box, boxes[j])\n",
    "            if iou > iou_threshold:\n",
    "                current_box = [\n",
    "                    min(current_box[0], boxes[j][0]),\n",
    "                    min(current_box[1], boxes[j][1]),\n",
    "                    max(current_box[2], boxes[j][2]),\n",
    "                    max(current_box[3], boxes[j][3])\n",
    "                ]\n",
    "                used[j] = True\n",
    "        \n",
    "        merged.append(current_box)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def draw_dashed_rect(img, pt1, pt2, color=(0, 255, 0), thickness=3, dash=10):\n",
    "    \"\"\"Draw dashed rectangle.\"\"\"\n",
    "    x1, y1 = pt1\n",
    "    x2, y2 = pt2\n",
    "\n",
    "    for x in range(x1, x2, dash * 2):\n",
    "        cv2.line(img, (x, y1), (min(x + dash, x2), y1), color, thickness)\n",
    "        cv2.line(img, (x, y2), (min(x + dash, x2), y2), color, thickness)\n",
    "\n",
    "    for y in range(y1, y2, dash * 2):\n",
    "        cv2.line(img, (x1, y), (x1, min(y + dash, y2)), color, thickness)\n",
    "        cv2.line(img, (x2, y), (x2, min(y + dash, y2)), color, thickness)\n",
    "\n",
    "print(\"âœ… Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5538cd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PDF conversion function defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: PDF to Images Conversion\n",
    "# ---------------- PDF â†’ IMAGES ----------------\n",
    "\n",
    "def pdf_to_images(pdf_path):\n",
    "    \"\"\"Convert PDF to high-resolution images.\"\"\"\n",
    "    print(f\"Converting PDF to images (DPI: {DPI})...\")\n",
    "    images = convert_from_path(pdf_path, dpi=DPI)\n",
    "    paths = []\n",
    "    for i, img in enumerate(images):\n",
    "        p = Path(OUTPUT_DIR) / f\"page_{i+1}.png\"\n",
    "        img.save(p, \"PNG\")\n",
    "        paths.append(str(p))\n",
    "    print(f\"âœ… Converted {len(paths)} pages\")\n",
    "    return paths\n",
    "\n",
    "print(\"âœ… PDF conversion function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc6ae845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Table detection methods defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Table Detection Methods\n",
    "# ---------------- TABLE DETECTION METHODS ----------------\n",
    "\n",
    "def detect_tables_detr(image_path, threshold):\n",
    "    \"\"\"Method 1: DETR Table Transformer detection.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = table_model(**inputs)\n",
    "\n",
    "    target_sizes = torch.tensor([image.size[::-1]])\n",
    "    results = processor.post_process_object_detection(\n",
    "        outputs, threshold=threshold, target_sizes=target_sizes\n",
    "    )[0]\n",
    "\n",
    "    return results[\"boxes\"].tolist()\n",
    "\n",
    "def detect_tables_opencv(image_path):\n",
    "    \"\"\"Method 2: OpenCV contour-based table detection.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Thresholding\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Detect horizontal and vertical lines\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))\n",
    "    \n",
    "    horizontal = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "    vertical = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel)\n",
    "    \n",
    "    # Combine lines\n",
    "    table_mask = cv2.add(horizontal, vertical)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    boxes = []\n",
    "    min_area = (img.shape[0] * img.shape[1]) * 0.01  # Minimum 1% of page\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        area = w * h\n",
    "        \n",
    "        if area > min_area and w > 100 and h > 100:\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "    \n",
    "    return boxes\n",
    "\n",
    "def detect_tables_all_methods(image_path):\n",
    "    \"\"\"Combine DETR and OpenCV detection methods.\"\"\"\n",
    "    all_boxes = []\n",
    "    \n",
    "    # Method 1: DETR (two-pass)\n",
    "    print(\"  ğŸ” DETR Pass 1 (threshold 0.6)...\")\n",
    "    boxes_detr_1 = detect_tables_detr(image_path, TABLE_THRESHOLD_PASS1)\n",
    "    print(f\"    Found: {len(boxes_detr_1)} tables\")\n",
    "    all_boxes.extend(boxes_detr_1)\n",
    "    \n",
    "    print(\"  ğŸ” DETR Pass 2 (threshold 0.4)...\")\n",
    "    boxes_detr_2 = detect_tables_detr(image_path, TABLE_THRESHOLD_PASS2)\n",
    "    print(f\"    Found: {len(boxes_detr_2)} tables\")\n",
    "    all_boxes.extend(boxes_detr_2)\n",
    "    \n",
    "    # Method 2: OpenCV\n",
    "    print(\"  ğŸ” OpenCV contour detection...\")\n",
    "    boxes_opencv = detect_tables_opencv(image_path)\n",
    "    print(f\"    Found: {len(boxes_opencv)} tables\")\n",
    "    all_boxes.extend(boxes_opencv)\n",
    "    \n",
    "    # Merge all detections\n",
    "    print(f\"  ğŸ“¦ Total boxes before merging: {len(all_boxes)}\")\n",
    "    merged = merge_boxes(all_boxes, IOU_THRESHOLD)\n",
    "    print(f\"  âœ… Final unique tables: {len(merged)}\")\n",
    "    \n",
    "    return merged\n",
    "\n",
    "print(\"âœ… Table detection methods defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf009fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Text extraction functions defined (COMPLETE)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Text Extraction Functions (COMPLETE FIX)\n",
    "# ---------------- TEXT EXTRACTION ----------------\n",
    "\n",
    "def extract_text_with_structure(image_path):\n",
    "    \"\"\"\n",
    "    Extract text with structure using Google Vision API.\n",
    "    Returns blocks with bounding boxes and full text.\n",
    "    \"\"\"\n",
    "    # Read image file\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    \n",
    "    # Create Vision API image object\n",
    "    image = vision.Image(content=content)\n",
    "    \n",
    "    # Perform document text detection\n",
    "    response = vision_client.document_text_detection(image=image)\n",
    "    \n",
    "    if response.error.message:\n",
    "        raise Exception(f\"Google Vision API error: {response.error.message}\")\n",
    "    \n",
    "    # Extract full text\n",
    "    full_text = response.full_text_annotation.text if response.full_text_annotation else \"\"\n",
    "    \n",
    "    # Extract structured blocks with bounding boxes\n",
    "    blocks = []\n",
    "    if response.full_text_annotation:\n",
    "        for page in response.full_text_annotation.pages:\n",
    "            for block in page.blocks:\n",
    "                # Get bounding box vertices\n",
    "                vertices = []\n",
    "                for vertex in block.bounding_box.vertices:\n",
    "                    vertices.append({\"x\": vertex.x, \"y\": vertex.y})\n",
    "                \n",
    "                # Extract text from block\n",
    "                block_text = \"\"\n",
    "                for paragraph in block.paragraphs:\n",
    "                    for word in paragraph.words:\n",
    "                        word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                        block_text += word_text + \" \"\n",
    "                \n",
    "                blocks.append({\n",
    "                    \"text\": block_text.strip(),\n",
    "                    \"bounding_box\": vertices\n",
    "                })\n",
    "    \n",
    "    return blocks, full_text\n",
    "\n",
    "\n",
    "def extract_text_google_vision(image_path):\n",
    "    \"\"\"Extract text using Google Vision OCR.\"\"\"\n",
    "    blocks, full_text = extract_text_with_structure(image_path)\n",
    "    return blocks, full_text\n",
    "\n",
    "\n",
    "def extract_table_text(image_path, table_box):\n",
    "    \"\"\"Extract text from a specific table region.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    x1, y1, x2, y2 = map(int, table_box)\n",
    "    \n",
    "    # Add padding to ensure we don't cut off text\n",
    "    padding = 5\n",
    "    x1 = max(0, x1 - padding)\n",
    "    y1 = max(0, y1 - padding)\n",
    "    x2 = min(img.shape[1], x2 + padding)\n",
    "    y2 = min(img.shape[0], y2 + padding)\n",
    "    \n",
    "    # Crop table region\n",
    "    table_img = img[y1:y2, x1:x2]\n",
    "    temp_path = Path(OUTPUT_DIR) / \"temp_table.png\"\n",
    "    cv2.imwrite(str(temp_path), table_img)\n",
    "    \n",
    "    # Extract with Google Vision\n",
    "    try:\n",
    "        vision_blocks, vision_text = extract_text_google_vision(str(temp_path))\n",
    "        \n",
    "        result = {\n",
    "            \"text_blocks\": vision_blocks,\n",
    "            \"full_text\": vision_text\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"    âš ï¸  Warning: OCR failed - {str(e)}\")\n",
    "        result = {\n",
    "            \"text_blocks\": [],\n",
    "            \"full_text\": f\"[OCR Error: {str(e)}]\"\n",
    "        }\n",
    "    finally:\n",
    "        # Clean up temp file\n",
    "        if temp_path.exists():\n",
    "            temp_path.unlink()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"âœ… Text extraction functions defined (COMPLETE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62ed5af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Main pipeline function defined (FIXED)\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Main Pipeline Function (FIXED)\n",
    "# ---------------- MAIN PIPELINE ----------------\n",
    "\n",
    "def is_text_inside_table(text_block, table_boxes):\n",
    "    \"\"\"Check if a text block is inside any table region.\"\"\"\n",
    "    # Get text block coordinates\n",
    "    if not text_block.get(\"bounding_box\"):\n",
    "        return False\n",
    "    \n",
    "    bbox = text_block[\"bounding_box\"]\n",
    "    if len(bbox) < 4:\n",
    "        return False\n",
    "    \n",
    "    # Calculate text block center point\n",
    "    text_x = sum([v.get(\"x\", 0) for v in bbox]) / len(bbox)\n",
    "    text_y = sum([v.get(\"y\", 0) for v in bbox]) / len(bbox)\n",
    "    \n",
    "    # Check if center point is inside any table\n",
    "    for table_box in table_boxes:\n",
    "        x1, y1, x2, y2 = table_box\n",
    "        if x1 <= text_x <= x2 and y1 <= text_y <= y2:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def run_pipeline(pdf_path):\n",
    "    \"\"\"Main processing pipeline.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸš€ STABLE TABLE DETECTION & TEXT EXTRACTION\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    pages = pdf_to_images(pdf_path)\n",
    "    result = {\"success\": True, \"method\": \"DETR + OpenCV + Google Vision\", \"pages\": []}\n",
    "    \n",
    "    # For formatted text output (tables only)\n",
    "    formatted_text_tables = []\n",
    "    \n",
    "    # For content text output (non-table text only with table location comments)\n",
    "    content_text = []\n",
    "    content_text.append(\"=\"*70)\n",
    "    content_text.append(\"BPHS PDF - FULL TEXT CONTENT (Excluding Table Data)\")\n",
    "    content_text.append(\"=\"*70)\n",
    "    content_text.append(\"\")\n",
    "\n",
    "    for page_num, page_img in enumerate(pages, start=1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ğŸ“„ Processing Page {page_num}/{len(pages)}\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        img = cv2.imread(page_img)\n",
    "\n",
    "        # DUAL-METHOD TABLE DETECTION\n",
    "        table_boxes = detect_tables_all_methods(page_img)\n",
    "        tables = []\n",
    "\n",
    "        # Draw and extract text from each table\n",
    "        for idx, box in enumerate(table_boxes, start=1):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            \n",
    "            # Draw detection box\n",
    "            draw_dashed_rect(img, (x1, y1), (x2, y2))\n",
    "\n",
    "            # Add label\n",
    "            label = f\"table_{idx}\"\n",
    "            label_pos = (x1 + 5, y1 - 10 if y1 > 30 else y1 + 25)\n",
    "            \n",
    "            (text_width, text_height), _ = cv2.getTextSize(\n",
    "                label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2\n",
    "            )\n",
    "            cv2.rectangle(\n",
    "                img,\n",
    "                (label_pos[0] - 2, label_pos[1] - text_height - 2),\n",
    "                (label_pos[0] + text_width + 2, label_pos[1] + 2),\n",
    "                (0, 255, 0), -1\n",
    "            )\n",
    "            \n",
    "            # FIX: Add all required parameters to putText\n",
    "            cv2.putText(\n",
    "                img, \n",
    "                label, \n",
    "                label_pos, \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,  # font\n",
    "                0.7,                        # fontScale\n",
    "                (0, 0, 0),                  # color (black text)\n",
    "                2,                          # thickness\n",
    "                cv2.LINE_AA                 # lineType\n",
    "            )\n",
    "\n",
    "            # Extract text from table\n",
    "            print(f\"  ğŸ“‹ Extracting Table {idx}...\")\n",
    "            table_text = extract_table_text(page_img, box)\n",
    "            \n",
    "            tables.append({\n",
    "                \"table_id\": f\"table_{idx}\",\n",
    "                \"bbox\": box,\n",
    "                \"text\": table_text\n",
    "            })\n",
    "            \n",
    "            # Add to formatted output\n",
    "            formatted_text_tables.append(f\"\\n{'='*70}\")\n",
    "            formatted_text_tables.append(f\"Page {page_num} - Table {idx}\")\n",
    "            formatted_text_tables.append(f\"{'='*70}\")\n",
    "            formatted_text_tables.append(table_text[\"full_text\"])\n",
    "\n",
    "        # Save annotated image\n",
    "        output_img_path = Path(OUTPUT_DIR) / f\"page_{page_num}_annotated.png\"\n",
    "        cv2.imwrite(str(output_img_path), img)\n",
    "        print(f\"  âœ… Saved annotated image: {output_img_path.name}\")\n",
    "\n",
    "        # Extract full page text for non-table content\n",
    "        print(f\"  ğŸ“ Extracting full page text...\")\n",
    "        page_blocks, page_text = extract_text_google_vision(page_img)\n",
    "        \n",
    "        # Add page header to content text\n",
    "        content_text.append(f\"\\n{'='*70}\")\n",
    "        content_text.append(f\"PAGE {page_num}\")\n",
    "        content_text.append(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Filter out text that's inside tables\n",
    "        non_table_blocks = []\n",
    "        for block in page_blocks:\n",
    "            if not is_text_inside_table(block, table_boxes):\n",
    "                non_table_blocks.append(block)\n",
    "        \n",
    "        # Add non-table text\n",
    "        for block in non_table_blocks:\n",
    "            content_text.append(block.get(\"text\", \"\"))\n",
    "        \n",
    "        # Add table location markers\n",
    "        if table_boxes:\n",
    "            content_text.append(f\"\\n[{len(table_boxes)} table(s) detected on this page - see tables.txt for content]\")\n",
    "\n",
    "        result[\"pages\"].append({\n",
    "            \"page\": page_num,\n",
    "            \"image\": str(output_img_path),\n",
    "            \"table_count\": len(tables),\n",
    "            \"tables\": tables\n",
    "        })\n",
    "\n",
    "    # Save formatted table text\n",
    "    table_text_path = Path(OUTPUT_DIR) / \"tables.txt\"\n",
    "    with open(table_text_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(formatted_text_tables))\n",
    "    print(f\"\\nâœ… Saved table text: {table_text_path}\")\n",
    "\n",
    "    # Save non-table content text\n",
    "    content_text_path = Path(OUTPUT_DIR) / \"content.txt\"\n",
    "    with open(content_text_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(content_text))\n",
    "    print(f\"âœ… Saved content text: {content_text_path}\")\n",
    "\n",
    "    # Save JSON\n",
    "    json_path = Path(OUTPUT_DIR) / \"results.json\"\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"âœ… Saved JSON: {json_path}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "print(\"âœ… Main pipeline function defined (FIXED)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c70761c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸš€ STABLE TABLE DETECTION & TEXT EXTRACTION\n",
      "======================================================================\n",
      "\n",
      "Converting PDF to images (DPI: 300)...\n",
      "âœ… Converted 25 pages\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 1/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 0 tables\n",
      "  ğŸ“¦ Total boxes before merging: 2\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_1_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 2/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 0 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 2 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 2 tables\n",
      "  ğŸ“¦ Total boxes before merging: 4\n",
      "  âœ… Final unique tables: 2\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  ğŸ“‹ Extracting Table 2...\n",
      "  âœ… Saved annotated image: page_2_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 3/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 0 tables\n",
      "  ğŸ“¦ Total boxes before merging: 2\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_3_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 4/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 1 tables\n",
      "  ğŸ“¦ Total boxes before merging: 3\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_4_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 5/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 2 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 2 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 2 tables\n",
      "  ğŸ“¦ Total boxes before merging: 6\n",
      "  âœ… Final unique tables: 2\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  ğŸ“‹ Extracting Table 2...\n",
      "  âœ… Saved annotated image: page_5_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 6/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 2 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 2 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 1 tables\n",
      "  ğŸ“¦ Total boxes before merging: 5\n",
      "  âœ… Final unique tables: 2\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  ğŸ“‹ Extracting Table 2...\n",
      "  âœ… Saved annotated image: page_6_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 7/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 2 tables\n",
      "  ğŸ“¦ Total boxes before merging: 4\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_7_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 8/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 1 tables\n",
      "  ğŸ“¦ Total boxes before merging: 3\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_8_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 9/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 0 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 2 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 2 tables\n",
      "  ğŸ“¦ Total boxes before merging: 4\n",
      "  âœ… Final unique tables: 2\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  ğŸ“‹ Extracting Table 2...\n",
      "  âœ… Saved annotated image: page_9_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 10/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 0 tables\n",
      "  ğŸ“¦ Total boxes before merging: 2\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_10_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 11/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 2 tables\n",
      "  ğŸ“¦ Total boxes before merging: 4\n",
      "  âœ… Final unique tables: 2\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  ğŸ“‹ Extracting Table 2...\n",
      "  âœ… Saved annotated image: page_11_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 12/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 1 tables\n",
      "  ğŸ“¦ Total boxes before merging: 3\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_12_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 13/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 2 tables\n",
      "  ğŸ“¦ Total boxes before merging: 4\n",
      "  âœ… Final unique tables: 2\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  ğŸ“‹ Extracting Table 2...\n",
      "  âœ… Saved annotated image: page_13_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 14/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 1 tables\n",
      "  ğŸ“¦ Total boxes before merging: 3\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_14_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 15/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 1 tables\n",
      "  ğŸ“¦ Total boxes before merging: 3\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_15_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 16/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 0 tables\n",
      "  ğŸ“¦ Total boxes before merging: 2\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_16_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 17/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 0 tables\n",
      "  ğŸ“¦ Total boxes before merging: 2\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_17_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 18/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 0 tables\n",
      "  ğŸ“¦ Total boxes before merging: 2\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_18_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 19/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 0 tables\n",
      "  ğŸ“¦ Total boxes before merging: 2\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_19_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 20/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 0 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 0 tables\n",
      "  ğŸ“¦ Total boxes before merging: 1\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_20_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 21/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 0 tables\n",
      "  ğŸ“¦ Total boxes before merging: 2\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_21_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 22/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 0 tables\n",
      "  ğŸ“¦ Total boxes before merging: 2\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_22_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 23/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 0 tables\n",
      "  ğŸ“¦ Total boxes before merging: 2\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_23_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 24/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 2 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 2 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 0 tables\n",
      "  ğŸ“¦ Total boxes before merging: 4\n",
      "  âœ… Final unique tables: 2\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  ğŸ“‹ Extracting Table 2...\n",
      "  âœ… Saved annotated image: page_24_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ Processing Page 25/25\n",
      "======================================================================\n",
      "  ğŸ” DETR Pass 1 (threshold 0.6)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” DETR Pass 2 (threshold 0.4)...\n",
      "    Found: 1 tables\n",
      "  ğŸ” OpenCV contour detection...\n",
      "    Found: 1 tables\n",
      "  ğŸ“¦ Total boxes before merging: 3\n",
      "  âœ… Final unique tables: 1\n",
      "  ğŸ“‹ Extracting Table 1...\n",
      "  âœ… Saved annotated image: page_25_annotated.png\n",
      "  ğŸ“ Extracting full page text...\n",
      "\n",
      "âœ… Saved table text: final_output\\tables.txt\n",
      "âœ… Saved content text: final_output\\content.txt\n",
      "âœ… Saved JSON: final_output\\results.json\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š SUMMARY STATISTICS\n",
      "======================================================================\n",
      "  Page  1: 1 table(s) detected\n",
      "  Page  2: 2 table(s) detected\n",
      "  Page  3: 1 table(s) detected\n",
      "  Page  4: 1 table(s) detected\n",
      "  Page  5: 2 table(s) detected\n",
      "  Page  6: 2 table(s) detected\n",
      "  Page  7: 1 table(s) detected\n",
      "  Page  8: 1 table(s) detected\n",
      "  Page  9: 2 table(s) detected\n",
      "  Page 10: 1 table(s) detected\n",
      "  Page 11: 2 table(s) detected\n",
      "  Page 12: 1 table(s) detected\n",
      "  Page 13: 2 table(s) detected\n",
      "  Page 14: 1 table(s) detected\n",
      "  Page 15: 1 table(s) detected\n",
      "  Page 16: 1 table(s) detected\n",
      "  Page 17: 1 table(s) detected\n",
      "  Page 18: 1 table(s) detected\n",
      "  Page 19: 1 table(s) detected\n",
      "  Page 20: 1 table(s) detected\n",
      "  Page 21: 1 table(s) detected\n",
      "  Page 22: 1 table(s) detected\n",
      "  Page 23: 1 table(s) detected\n",
      "  Page 24: 2 table(s) detected\n",
      "  Page 25: 1 table(s) detected\n",
      "\n",
      "âœ… All files saved in: final_output\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "#  Cell 10: Run the Pipeline\n",
    "# ---------------- EXECUTE PROCESSING ----------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = run_pipeline(PDF_PATH)\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“Š SUMMARY STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for page_data in result[\"pages\"]:\n",
    "        page_num = page_data[\"page\"]\n",
    "        table_count = page_data[\"table_count\"]\n",
    "        print(f\"  Page {page_num:2d}: {table_count} table(s) detected\")\n",
    "    \n",
    "    print(\"\\nâœ… All files saved in:\", OUTPUT_DIR)\n",
    "    print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
